{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "from numpy import linalg as linalg\n",
    "import matplotlib.pyplot as plt\n",
    "#read data\n",
    "filename = \"data-Mini Project 2.h5\"\n",
    "with h5py.File(filename, \"r\") as f:\n",
    "    f.keys()\n",
    "    trX = np.array(f[\"trX\"])\n",
    "    trY = np.array(f[\"trY\"])\n",
    "    tstX  = np.array(f[\"tstX\"])\n",
    "    tstY  = np.array(f[\"tstY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize data\n",
    "trX = (trX - np.mean(trX, axis=0)) / np.std(trX, axis=0)\n",
    "tstX = (tstX - np.mean(tstX, axis=0)) / np.std(tstX, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mix the data since data is distributed uniformly\n",
    "ahsen = np.random.permutation(600)\n",
    "tstX_rand=tstX[ahsen]\n",
    "tstY_rand=tstY[ahsen]\n",
    "assen =np.random.permutation(3000)\n",
    "trX_rand=trX[assen]\n",
    "trY_rand = trY[assen]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize paramteres\n",
    "N=50\n",
    "bs = 30\n",
    "learning_rate = 0.003\n",
    "weight_ih = np.random.uniform(low=-0.1,high=0.1,size=(N,3))\n",
    "weight_hh = np.random.uniform(low=-0.1,high=0.1,size=(N,N))\n",
    "weight_ho = np.random.uniform(low=-0.1,high=0.1,size=(6,N))\n",
    "b = np.random.uniform(low=-0.1,high=0.1,size=(N,1)) #bias for wih\n",
    "c = np.random.uniform(low=-0.1,high=0.1,size=(6,1)) #bias for who\n",
    "weight_hh_up = np.zeros((N,N))\n",
    "weight_ih_up = np.zeros((N,3))\n",
    "weight_ho_up = np.zeros((6,N))\n",
    "c_updated = np.zeros((6,1))\n",
    "b_updated = np.zeros((N,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#activation functions and their derivatives\n",
    "def sigmoid(v):\n",
    "    return np.ones((len(v),1))/(np.ones((len(v),1))+ np.exp(-v)) \n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def tanh_derivative(x):\n",
    "    return 1 - np.tanh(x)**2\n",
    "#forward propagation\n",
    "def f_propagation(weight_ih,weight_hh,weight_ho,b,c,N,X):\n",
    "    #initialize an empty array to hold previous values of outputs and h \n",
    "    hlist = np.zeros((len(X)+1,N,1))\n",
    "    ylist = np.zeros((len(X),6,1))\n",
    "    memo = np.zeros((N,1)) #previous data from forward (t-1)\n",
    "    for t in range(150): #find for each 150 section\n",
    "        vh= np.matmul(weight_ih,X[t].reshape((3,1)))\n",
    "        vh = vh +np.matmul(weight_hh,memo)+ b \n",
    "        hidden = np.tanh(vh)\n",
    "        vo = np.dot(weight_ho,hidden) + c\n",
    "        out = sigmoid(vo)\n",
    "        ylist[t] = out #add final outputs to array\n",
    "        memo = hidden #holf temporary data\n",
    "        hlist[t+1] = memo #add temp to later value of h\n",
    "    return ylist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "1.4437448149208536\n",
      "Epoch 2\n",
      "1.118843177106805\n",
      "Epoch 3\n",
      "0.9956398745910906\n",
      "Epoch 4\n",
      "0.8411173769699546\n",
      "Epoch 5\n",
      "0.9105613481418134\n",
      "Epoch 6\n",
      "0.7620315802753324\n"
     ]
    }
   ],
   "source": [
    "#training begins first forward then back \n",
    "for e in range(6): #epoch number\n",
    "    print(\"Epoch\", e+1) #track each epoch\n",
    "    equal=0\n",
    "    mean_error=0  #initialize mena error to 0 in every epoch \n",
    "    for element in range(150): #lenght of one data\n",
    "        desiredifference= trY_rand[element].reshape((1,6)) #take training y data\n",
    "        X=trX_rand[element] #takr training X data (line by line)\n",
    "        hlist = np.zeros((150,N,1)) #assign an empty array to hold all h values\n",
    "        ylist = np.zeros((150,6,1)) #assign an empty array to hold all output values\n",
    "        memo = np.zeros((N,1)) #memory hold h(t-1)\n",
    "        mean_error = 0\n",
    "        for num in range(150//bs): #divide to batches\n",
    "            #forward_propagation\n",
    "            #same with def f_propagation\n",
    "            for r in range(bs*num,bs*(num+1)):\n",
    "                vh1=np.matmul(weight_ih, X[r].reshape((3,1)))\n",
    "                vh = vh1 + np.matmul(weight_hh,hlist[r-1]) + b\n",
    "                hidden = np.tanh(vh)\n",
    "                vo = np.matmul(weight_ho,hidden) + c\n",
    "                out = sigmoid(vo)\n",
    "                ylist[r] = out\n",
    "                hlist[r] = hidden #temp data\n",
    "                #entropy formula\n",
    "                total_error = -np.matmul(desiredifference,np.log(abs(out+1e-8)))-np.matmul((np.ones((1,6))-desiredifference),np.log(abs(np.ones((6,1))-out)+1e-8))\n",
    "                #take mean of the total error \n",
    "                total_error=total_error.mean()\n",
    "                #total_error = -np.matmul(desiredifference,np.log(out))-np.matmul(np.ones(shape=(1,6))-desiredifference,np.log(np.ones(shape=(6,1))-out))\n",
    "                \n",
    "                if not np.isnan(total_error): #to avoid possible nan values check if it is nan or not\n",
    "                    mean_error = mean_error+ total_error/150 #mena_error divided by length of x\n",
    "                #else:\n",
    "                    #print(\"Value is nan\")\n",
    "                    \n",
    "                #backpropagation begins (bptt)\n",
    "                \n",
    "                difference =ylist[bs*(num+1)-1] - desiredifference.reshape((6,1)) #difference=d-o ##(desired- output)\n",
    "                diff = np.matmul(weight_ho.reshape((50,6)),difference)\n",
    "                weight_ho_up = weight_ho_up + np.matmul(difference,hlist[bs*(num+1)-1].reshape((1,50))) #easiest to update since no (t-1) dependancy\n",
    "                c_updated = c_updated+ difference #also update biases by using d-o (after who)\n",
    "                \n",
    "                #tanh derivative is needed to update other weigths and biases\n",
    "                temp=(np.ones((1,N))-np.square(hlist[bs*(num+1)-1].reshape((1,50)))).flatten() #take the las value of hlist subtract by one \n",
    "                back_inp = np.matmul(np.diag(temp),diff) \n",
    "                b_updated =b_updated + back_inp #update bias for who before\n",
    "                weight_hh_up =weight_hh_up+ np.matmul(back_inp,hlist[bs*(num+1)-2].reshape((1,50)))\n",
    "                weight_ih_up = weight_ih_up+ np.matmul(back_inp,X[bs-1+num*bs].reshape((1,3)))\n",
    "                for j in range(bs*(num+1)-2,bs*num,-1): #going back\n",
    "                    difference = ylist[j] - desiredifference.reshape((6,1)) #d-o tersten al ylisti\n",
    "                    diff = np.matmul(np.diag((np.ones((1,N))-np.square(hlist[j+1].reshape((1,50)))).flatten()),diff) #tanh derivative\n",
    "                    diff = np.matmul(weight_hh.T,diff)\n",
    "                    diff = diff + np.matmul(weight_ho.reshape((50,6)),difference)\n",
    "                    c_updated = c_updated+difference\n",
    "                    weight_ho_up = weight_ho_up+np.matmul(difference,hlist[j].reshape((1,50)))\n",
    "                    back_inp = np.matmul(np.diag((np.ones((1,N))-np.square(hlist[j].reshape((1,50)))).flatten()),diff)\n",
    "                    b_updated =  b_updated+back_inp\n",
    "                    weight_hh_up = weight_hh_up+np.matmul(back_inp,hlist[j-1].reshape((1,50)))\n",
    "                    weight_ih_up = weight_ih_up+ np.matmul(back_inp,X[j].reshape((1,3)))\n",
    "\n",
    "                    #weight_hh_up=10/np.linalg.norm(weight_hh_up)*weight_hh_up\n",
    "                    #weight_ih_up=10/np.linalg.norm(weight_ih_up)*weight_ih_up\n",
    "                    #weight_ho_up=10/np.linalg.norm(weight_ho_up)*weight_ho_up\n",
    "                    #b_updated=10/np.linalg.norm(b_updated)*b_updated\n",
    "                    #c_updated=10/np.linalg.norm(b_updated)*c_updated\n",
    "                    \n",
    "\n",
    "                    #if not np.isnan(weight_hh_up.mean()):\n",
    "                    weight_ih = weight_ih - learning_rate*weight_ih_up/(10*bs)\n",
    "                    weight_hh = weight_hh - learning_rate*weight_hh_up/(10*bs)\n",
    "                    weight_ho = weight_ho - learning_rate*weight_ho_up/(10*bs)\n",
    "\n",
    "                    b = b - learning_rate*b_updated/(10*bs) \n",
    "                    c = c - learning_rate*c_updated/(10*bs)\n",
    "                    \n",
    "                    weight_ih = (weight_ih - np.mean(weight_ih, axis=0)) / np.std(weight_ih, axis=0)\n",
    "                    weight_hh = (weight_hh - np.mean(weight_hh, axis=0)) / np.std(weight_hh, axis=0)\n",
    "                    weight_ho = (weight_ho - np.mean(weight_ho, axis=0)) / np.std(weight_ho, axis=0)\n",
    "\n",
    "\n",
    "                    b = (b - np.mean(b, axis=0)) / np.std(b, axis=0)\n",
    "                    c = (c - np.mean(c, axis=0)) / np.std(c, axis=0)\n",
    "\n",
    "\n",
    "                mean_error = mean_error+ np.mean(total_error)\n",
    "        #mean_error= (mean_error - np.mean(mean_error, axis=0)) / np.std(mean_error, axis=0)\n",
    "\n",
    "    print(mean_error/3000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.59181814 -0.59175199  0.59182755 ... -0.59189964  0.59180278\n",
      "   0.59175827]\n",
      " [-2.0361248   2.03606734 -2.03613311 ...  2.0361974  -2.03611121\n",
      "  -2.03607254]\n",
      " [ 0.03816101 -0.03807365  0.03817358 ... -0.03827149  0.03814045\n",
      "   0.03808166]\n",
      " ...\n",
      " [-0.00326995  0.00317879 -0.00328301 ...  0.00338172 -0.00324858\n",
      "  -0.00318715]\n",
      " [ 0.63045207 -0.63038988  0.63046091 ... -0.63052828  0.63043762\n",
      "   0.63039579]\n",
      " [ 1.41186554 -1.4118159   1.41187266 ... -1.41192759  1.41185391\n",
      "   1.41182055]]\n"
     ]
    }
   ],
   "source": [
    "print(weight_hh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.expand_dims(X[5],axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 19.5\n",
      "585\n"
     ]
    }
   ],
   "source": [
    "equal = 0#find the number of correct predictions d=o\n",
    "for i in range(3000):\n",
    "    if (np.argmax(trY[i])==np.argmax(f_propagation(weight_ih,weight_hh,weight_ho,b,c,N,X=trX[i])[0:150].mean(axis=0))):\n",
    "        equal+=1\n",
    "accuracy=100*equal/len(trY)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(equal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 14.0\n",
      "84\n"
     ]
    }
   ],
   "source": [
    "equal = 0#find the number of correct predictions d=o\n",
    "for i in range(600):\n",
    "    if (np.argmax(tstY[i])==np.argmax(f_propagation(weight_ih,weight_hh,weight_ho,b,c,N,X=tstX[i])[0:150].mean(axis=0))):\n",
    "        equal+=1\n",
    "accuracy=100*equal/len(tstY)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(equal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 16.433333333333334\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for element in range(15): #epoch\n",
    "    equal = 0 #find the number of correct predictions d=o\n",
    "    for i in range(3000):\n",
    "        X=trX_rand[i]\n",
    "        #f_propagation \n",
    "        for t in range(len(X)-1):\n",
    "            vh = np.dot(weight_ih,np.expand_dims(X[t],axis=0).T) + np.dot(weight_hh,memo)+ b\n",
    "            hidden = np.tanh(vh)\n",
    "            vo = np.dot(weight_ho,hidden) + c\n",
    "            out = sigmoid(vo)\n",
    "            ylist[t] = out\n",
    "            memo = hidden\n",
    "            hlist[t+1] = memo\n",
    "        if (np.argmax(trY[i])==np.argmax(ylist[0:150].mean(axis=0))):\n",
    "            equal=equal+ 1\n",
    "accuracy=100*equal/3000\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 17.166666666666668\n"
     ]
    }
   ],
   "source": [
    "for element in range(15):\n",
    "    equal = 0\n",
    "    for i in range(600):\n",
    "        X=tstX_rand[i]\n",
    "        #f_propagation \n",
    "        for t in range(len(X)-1):\n",
    "            vh = np.dot(weight_ih,np.expand_dims(X[t],axis=0).T) + np.dot(weight_hh,memo)+ b\n",
    "            hidden = np.tanh(vh)\n",
    "            vo = np.dot(weight_ho,hidden) + c\n",
    "            out = sigmoid(vo)\n",
    "            ylist[t] = out\n",
    "            memo = hidden\n",
    "            hlist[t+1] = memo\n",
    "        if (np.argmax(tstY[i])==np.argmax(ylist.mean(axis=0))):\n",
    "            equal=equal+ 1\n",
    "accuracy=100*equal/600\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_top123(weight_ih,weight_hh,weight_ho,b,c,N,tstX,tstY):\n",
    "    accuracy_top1 = 0\n",
    "    accuracy_top2 = 0\n",
    "    accuracy_top3 = 0\n",
    "    for top in range(600):\n",
    "        index_array = np.argsort(f_propagation(weight_ih,weight_hh,weight_ho,b,c,N,tstX[top]).mean(axis=0).flatten())\n",
    "        desired_out = np.argmax(tstY[top])\n",
    "        if desired_out == index_array[-1]:\n",
    "            accuracy_top1= accuracy_top1+1\n",
    "            accuracy_top2= accuracy_top2+1\n",
    "            accuracy_top3= accuracy_top3+1\n",
    "            \n",
    "        \n",
    "\n",
    "        elif desired_out == index_array[-2]:   \n",
    "            accuracy_top2= accuracy_top2+1\n",
    "            accuracy_top3= accuracy_top3+1\n",
    "            \n",
    "        elif desired_out == index_array[-3]:  \n",
    "            accuracy_top3= accuracy_top3+1\n",
    "    return 100*accuracy_top1/600,100*accuracy_top2/600,100*accuracy_top3/600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14.0, 31.333333333333332, 57.333333333333336)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_top123(weight_ih,weight_hh,weight_ho,b,c,N,tstX,tstY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.5, 11.833333333333334, 87.16666666666667)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_top123(weight_ih,weight_hh,weight_ho,b,c,N,trX,trY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## VALIDATION LOSS FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 1 into shape (1,6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-14a6c275f143>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mval_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalculate_validation_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtstY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight_ih\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight_hh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight_ho\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Validation Loss:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-14a6c275f143>\u001b[0m in \u001b[0;36mcalculate_validation_loss\u001b[1;34m(X_val, y_val, weight_ih, weight_hh, weight_ho, b, c)\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mylist_val\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mout_val\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mhlist_val\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhidden_val\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         total_error_val = -np.matmul(y_val[i].reshape((1, 6)), np.log(abs(out_val + 1e-8))) - np.matmul(\n\u001b[0m\u001b[0;32m     15\u001b[0m             (np.ones((1, 6)) - y_val[i]), np.log(abs(np.ones((6, 1)) - out_val) + 1e-8))\n\u001b[0;32m     16\u001b[0m         \u001b[0mtotal_error_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtotal_error_val\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 1 into shape (1,6)"
     ]
    }
   ],
   "source": [
    "def calculate_validation_loss(X_val, y_val, weight_ih, weight_hh, weight_ho, b, c):\n",
    "    val_loss = 0\n",
    "    hlist_val = np.zeros((X_val.shape[0], N, 1))\n",
    "    ylist_val = np.zeros((X_val.shape[0], 6, 1))\n",
    "\n",
    "    for i in range(X_val.shape[0]):\n",
    "        vh1_val = np.matmul(weight_ih, X_val[i].reshape((3, 1)))\n",
    "        vh_val = vh1_val + np.matmul(weight_hh, hlist_val[i - 1]) + b\n",
    "        hidden_val = np.tanh(vh_val)\n",
    "        vo_val = np.matmul(weight_ho, hidden_val) + c\n",
    "        out_val = sigmoid(vo_val)\n",
    "        ylist_val[i] = out_val\n",
    "        hlist_val[i] = hidden_val\n",
    "        total_error_val = -np.matmul(y_val[i].reshape((1, 6)), np.log(abs(out_val + 1e-8))) - np.matmul(\n",
    "            (np.ones((1, 6)) - y_val[i]), np.log(abs(np.ones((6, 1)) - out_val) + 1e-8))\n",
    "        total_error_val = total_error_val.mean()\n",
    "        if not np.isnan(total_error_val):\n",
    "            val_loss = val_loss + total_error_val / X_val.shape[0]\n",
    "\n",
    "    return val_loss\n",
    "\n",
    "val_loss = calculate_validation_loss(X, tstY[3], weight_ih, weight_hh, weight_ho, b, c)\n",
    "print(\"Validation Loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# EARLY STOPPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patience = 5\n",
    "##best_val_loss = \n",
    "early_stopping_counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
